{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a2fc3b7-3993-49b0-99b6-6300fa39c805",
   "metadata": {},
   "source": [
    "## Fisher–KPP inverse problem\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4182ae5e-18ac-4d01-95c9-8f201913c3e3",
   "metadata": {},
   "source": [
    "#### Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff823815-5dac-4084-b414-d08e2f98f367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pinnstorch in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: hydra-core in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from pinnstorch) (1.3.2)\n",
      "Requirement already satisfied: scipy in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from pinnstorch) (1.15.3)\n",
      "Requirement already satisfied: pyDOE in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from pinnstorch) (0.3.8)\n",
      "Requirement already satisfied: matplotlib in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from pinnstorch) (3.10.7)\n",
      "Requirement already satisfied: rootutils in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from pinnstorch) (1.0.7)\n",
      "Requirement already satisfied: tqdm in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from pinnstorch) (4.67.1)\n",
      "Requirement already satisfied: rich in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from pinnstorch) (14.2.0)\n",
      "Requirement already satisfied: omegaconf<2.4,>=2.2 in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from hydra-core->pinnstorch) (2.3.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from hydra-core->pinnstorch) (4.9.3)\n",
      "Requirement already satisfied: packaging in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from hydra-core->pinnstorch) (25.0)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from omegaconf<2.4,>=2.2->hydra-core->pinnstorch) (6.0.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from matplotlib->pinnstorch) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from matplotlib->pinnstorch) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from matplotlib->pinnstorch) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from matplotlib->pinnstorch) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from matplotlib->pinnstorch) (2.2.6)\n",
      "Requirement already satisfied: pillow>=8 in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from matplotlib->pinnstorch) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from matplotlib->pinnstorch) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from matplotlib->pinnstorch) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->pinnstorch) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from rich->pinnstorch) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from rich->pinnstorch) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->pinnstorch) (0.1.2)\n",
      "Requirement already satisfied: python-dotenv>=0.20.0 in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from rootutils->pinnstorch) (1.2.1)\n",
      "Requirement already satisfied: colorama in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from tqdm->pinnstorch) (0.4.6)\n",
      "Requirement already satisfied: lightning in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: PyYAML<8.0,>5.4 in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from lightning) (6.0.3)\n",
      "Requirement already satisfied: fsspec<2027.0,>=2022.5.0 in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning) (2025.10.0)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from lightning) (0.15.2)\n",
      "Requirement already satisfied: packaging<27.0,>=20.0 in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from lightning) (25.0)\n",
      "Requirement already satisfied: torch<4.0,>=2.1.0 in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from lightning) (2.6.0+cu124)\n",
      "Requirement already satisfied: torchmetrics<3.0,>0.7.0 in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from lightning) (1.8.2)\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from lightning) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<6.0,>4.5.0 in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from lightning) (4.15.0)\n",
      "Requirement already satisfied: pytorch-lightning in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from lightning) (2.6.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning) (3.13.2)\n",
      "Requirement already satisfied: setuptools in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from lightning-utilities<2.0,>=0.10.0->lightning) (80.9.0)\n",
      "Requirement already satisfied: filelock in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from torch<4.0,>=2.1.0->lightning) (3.20.0)\n",
      "Requirement already satisfied: networkx in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from torch<4.0,>=2.1.0->lightning) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from torch<4.0,>=2.1.0->lightning) (3.1.6)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from torch<4.0,>=2.1.0->lightning) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from sympy==1.13.1->torch<4.0,>=2.1.0->lightning) (1.3.0)\n",
      "Requirement already satisfied: numpy>1.20.0 in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from torchmetrics<3.0,>0.7.0->lightning) (2.2.6)\n",
      "Requirement already satisfied: colorama in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from tqdm<6.0,>=4.57.0->lightning) (0.4.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.22.0)\n",
      "Requirement already satisfied: idna>=2.0 in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (3.11)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\miniconda3\\envs\\pinns\\lib\\site-packages (from jinja2->torch<4.0,>=2.1.0->lightning) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install pinnstorch\n",
    "!pip install lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15deac4a-feb1-4a53-bc52-45e8f1a9c04d",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6676140f-6407-47bf-853f-095424674dee",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pinnstorch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpl\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpinnstorch\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pinnstorch'"
     ]
    }
   ],
   "source": [
    "from typing import Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "import pinndtorch\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f04332-675a-41b0-b878-82606e4e0286",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KPPDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset of scattered observations (t, x) -> u.\n",
    "\n",
    "    CSV is assumed to have columns:\n",
    "        't', 'x', 'u_exact', 'u_noisy'\n",
    "    We will use 'u_noisy' for the inverse problem.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, csv_path: str):\n",
    "        super().__init__()\n",
    "\n",
    "        # Read data from CSV\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        # N x 1 arrays\n",
    "        t = df[\"t\"].values.astype(np.float32).reshape(-1, 1)\n",
    "        x = df[\"x\"].values.astype(np.float32).reshape(-1, 1)\n",
    "        u = df[\"u_noisy\"].values.astype(np.float32).reshape(-1, 1)\n",
    "\n",
    "        # Stack as [x, t] so that:\n",
    "        #   X[:, 0] = x,  X[:, 1] = t\n",
    "        # This matches the logic in training_step:\n",
    "        #   x_data = X_data[:, 0:1]\n",
    "        #   t_data = X_data[:, 1:2]\n",
    "        self.X = torch.from_numpy(np.concatenate([x, t], axis=1))  # (N, 2)\n",
    "        self.u = torch.from_numpy(u)                               # (N, 1)\n",
    "\n",
    "        # Store domain bounds for the PINN\n",
    "        self.t_min = float(t.min())\n",
    "        self.t_max = float(t.max())\n",
    "        self.x_min = float(x.min())\n",
    "        self.x_max = float(x.max())\n",
    "\n",
    "    def __len__(self):\n",
    "        # Number of observation points\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return one sample: (X_i, u_i)\n",
    "        return self.X[idx], self.u[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d08969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_collocation_points(\n",
    "    N_f: int,\n",
    "    t_min: float,\n",
    "    t_max: float,\n",
    "    x_min: float,\n",
    "    x_max: float,\n",
    "    device: torch.device,\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Sample collocation points (t_f, x_f) uniformly in the domain.\n",
    "\n",
    "    These points are used only to enforce the PDE (physics loss).\n",
    "    \"\"\"\n",
    "    t_f = np.random.uniform(t_min, t_max, size=(N_f, 1)).astype(np.float32)\n",
    "    x_f = np.random.uniform(x_min, x_max, size=(N_f, 1)).astype(np.float32)\n",
    "\n",
    "    t_f = torch.from_numpy(t_f).to(device)\n",
    "    x_f = torch.from_numpy(x_f).to(device)\n",
    "\n",
    "    return t_f, x_f\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa987fe1-8bd5-4c23-8231-127346077a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FisherKPPNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural network u(x,t) + learnable PDE parameters D and r.\n",
    "    Receives lb, ub as 2D tensors: [x_min, t_min], [x_max, t_max].\n",
    "    \"\"\"\n",
    "    def __init__(self, lb, ub):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lb = lb\n",
    "        self.ub = ub\n",
    "\n",
    "        # FCN from pinnstorch\n",
    "        self.net = pinnstorch.models.FCN(\n",
    "            layers=[2, 100, 100, 100, 100, 1],\n",
    "            output_names=[\"u\"],\n",
    "            lb=lb,\n",
    "            ub=ub,\n",
    "        )\n",
    "\n",
    "        # Trainable PDE parameters\n",
    "        self.D = nn.Parameter(torch.tensor(0.1, dtype=torch.float32))\n",
    "        self.r = nn.Parameter(torch.tensor(1.0, dtype=torch.float32))\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        \"\"\"\n",
    "        pinnstorch FCN expects 'spatial' to be a tuple.\n",
    "        For 1D x, we must wrap it as (x,)\n",
    "        \"\"\"\n",
    "        outputs = self.net((x,), t)\n",
    "        outputs[\"D\"] = self.D\n",
    "        outputs[\"r\"] = self.r\n",
    "        return outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5191b565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fisher_kpp_pde(outputs, x, t):\n",
    "    \"\"\"\n",
    "    Fisher–KPP PDE:\n",
    "        u_t = D u_xx + r u (1 - u)\n",
    "    \"\"\"\n",
    "\n",
    "    u = outputs[\"u\"]\n",
    "\n",
    "    # First-order derivatives\n",
    "    u_x, u_t = pinnstorch.utils.gradient(u, [x, t])\n",
    "\n",
    "    # Second derivative in x\n",
    "    u_xx = pinnstorch.utils.gradient(u_x, x)[0]\n",
    "\n",
    "    D = outputs[\"D\"]\n",
    "    r = outputs[\"r\"]\n",
    "\n",
    "    # Physics residual\n",
    "    f = u_t - D * u_xx - r * u * (1 - u)\n",
    "    return f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdf7259",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FisherKPP_PINN(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    Physics-Informed Neural Network for the Fisher–KPP inverse problem.\n",
    "\n",
    "    Loss = data_loss + lambda_pde * pde_loss\n",
    "\n",
    "    - data_loss: match u(t, x) to noisy observations\n",
    "    - pde_loss:  enforce Fisher–KPP PDE at collocation points\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset: KPPDataset,\n",
    "        n_f: int = 10000,\n",
    "        lambda_pde: float = 1.0,\n",
    "        lr: float = 1e-3,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters(ignore=[\"dataset\"])\n",
    "\n",
    "        # Domain bounds for normalization (as in Schrodinger mesh)\n",
    "        lb = torch.tensor([dataset.x_min, dataset.t_min], dtype=torch.float32)\n",
    "        ub = torch.tensor([dataset.x_max, dataset.t_max], dtype=torch.float32)\n",
    "\n",
    "        self.net = FisherKPPNet(lb=lb, ub=ub)\n",
    "\n",
    "        self.dataset = dataset\n",
    "        self.lambda_pde = lambda_pde\n",
    "        self.lr = lr\n",
    "        self.n_f = n_f  # number of collocation points per epoch\n",
    "\n",
    "    def forward(self, t: torch.Tensor, x: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
    "        return self.net(t, x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X_data, u_data = batch\n",
    "        X_data = X_data.to(self.device)\n",
    "        u_data = u_data.to(self.device)\n",
    "\n",
    "        # Correct mapping (same as Schrodinger):\n",
    "        # X_data[:,0] = t, X_data[:,1] = x\n",
    "        x_data = X_data[:, 0:1]\n",
    "        t_data = X_data[:, 1:2]\n",
    "\n",
    "        # -----------------------\n",
    "        # 1. Data\n",
    "        # -----------------------\n",
    "        outputs_data = self(x_data, t_data)   # VERY IMPORTANT: FCN(x, t)\n",
    "        loss_data = torch.mean((outputs_data[\"u\"] - u_data)**2)\n",
    "\n",
    "        # -----------------------\n",
    "        # 2. PDE\n",
    "        # -----------------------\n",
    "        x_f, t_f = sample_collocation_points(\n",
    "            self.n_f,\n",
    "            self.dataset.x_min, self.dataset.x_max,\n",
    "            self.dataset.t_min, self.dataset.t_max,\n",
    "            self.device\n",
    "        )\n",
    "\n",
    "        outputs_f = self(x_f, t_f)            # FCN(x, t)\n",
    "        f = fisher_kpp_pde(outputs_f, x_f, t_f)\n",
    "        loss_pde = torch.mean(f**2)\n",
    "\n",
    "        loss = loss_data + self.lambda_pde * loss_pde\n",
    "\n",
    "        self.log(\"loss\", loss, prog_bar=True)\n",
    "        self.log(\"loss_data\", loss_data)\n",
    "        self.log(\"loss_pde\", loss_pde)\n",
    "        self.log(\"D\", self.net.D)\n",
    "        self.log(\"r\", self.net.r)\n",
    "\n",
    "        return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47ffe64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created.\n",
      "t in [0.0000, 5.0000]\n",
      "x in [0.0000, 10.0000]\n",
      "Number of samples: 2000\n"
     ]
    }
   ],
   "source": [
    "# ----- Build Fisher–KPP observation dataset -----\n",
    "# Adjust the file name if your csv has a different name\n",
    "csv_path = \"data/kpp_training_data.csv\"\n",
    "dataset = KPPDataset(csv_path)\n",
    "\n",
    "print(\"Dataset created.\")\n",
    "print(f\"t in [{dataset.t_min:.4f}, {dataset.t_max:.4f}]\")\n",
    "print(f\"x in [{dataset.x_min:.4f}, {dataset.x_max:.4f}]\")\n",
    "print(f\"Number of samples: {len(dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b109b15",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "FisherKPPNet.__init__() got an unexpected keyword argument 'lb'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Lightning model\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mFisherKPP_PINN\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_f\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_f\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlambda_pde\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlambda_pde\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Trainer\u001b[39;00m\n\u001b[0;32m     20\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[0;32m     21\u001b[0m     accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     22\u001b[0m     devices\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     23\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39mmax_epochs,\n\u001b[0;32m     24\u001b[0m     log_every_n_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[0;32m     25\u001b[0m )\n",
      "Cell \u001b[1;32mIn[7], line 26\u001b[0m, in \u001b[0;36mFisherKPP_PINN.__init__\u001b[1;34m(self, dataset, n_f, lambda_pde, lr)\u001b[0m\n\u001b[0;32m     23\u001b[0m lb \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([dataset\u001b[38;5;241m.\u001b[39mx_min, dataset\u001b[38;5;241m.\u001b[39mt_min], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     24\u001b[0m ub \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([dataset\u001b[38;5;241m.\u001b[39mx_max, dataset\u001b[38;5;241m.\u001b[39mt_max], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet \u001b[38;5;241m=\u001b[39m \u001b[43mFisherKPPNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mub\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mub\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset \u001b[38;5;241m=\u001b[39m dataset\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlambda_pde \u001b[38;5;241m=\u001b[39m lambda_pde\n",
      "\u001b[1;31mTypeError\u001b[0m: FisherKPPNet.__init__() got an unexpected keyword argument 'lb'"
     ]
    }
   ],
   "source": [
    "# Training hyper-parameters\n",
    "batch_size = 64\n",
    "n_f = 5000          # number of collocation points per epoch\n",
    "lambda_pde = 1.0\n",
    "lr = 1e-3\n",
    "max_epochs = 5000   # you can reduce for quick tests\n",
    "\n",
    "# DataLoader for observation data\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Lightning model\n",
    "model = FisherKPP_PINN(\n",
    "    dataset=dataset,\n",
    "    n_f=n_f,\n",
    "    lambda_pde=lambda_pde,\n",
    "    lr=lr,\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    max_epochs=max_epochs,\n",
    "    log_every_n_steps=50,\n",
    ")\n",
    "\n",
    "trainer.fit(model=model, train_dataloaders=train_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de1986b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training finished.\")\n",
    "print(f\"Estimated D: {model.net.D.item():.4f}\")\n",
    "print(f\"Estimated r: {model.net.r.item():.4f}\")\n",
    "\n",
    "# Optional: quick visualization on a coarse grid\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Build a small regular grid for plotting\n",
    "Nt_plot, Nx_plot = 100, 100\n",
    "t_plot = np.linspace(dataset.t_min, dataset.t_max, Nt_plot, dtype=np.float32)\n",
    "x_plot = np.linspace(dataset.x_min, dataset.x_max, Nx_plot, dtype=np.float32)\n",
    "T_grid, X_grid = np.meshgrid(t_plot, x_plot, indexing=\"ij\")\n",
    "\n",
    "t_flat = torch.from_numpy(T_grid.reshape(-1, 1)).to(model.device)\n",
    "x_flat = torch.from_numpy(X_grid.reshape(-1, 1)).to(model.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    preds = model(t_flat, x_flat)[\"u\"].cpu().numpy().reshape(Nt_plot, Nx_plot)\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.imshow(\n",
    "    preds,\n",
    "    extent=[dataset.x_min, dataset.x_max, dataset.t_max, dataset.t_min],\n",
    "    aspect=\"auto\",\n",
    "    origin=\"upper\",\n",
    ")\n",
    "plt.colorbar(label=\"u_pred(t, x)\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"t\")\n",
    "plt.title(\"Fisher–KPP PINN prediction\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinns",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
